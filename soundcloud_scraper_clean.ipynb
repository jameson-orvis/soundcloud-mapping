{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infinitely scrolls to the bottom of the page given by url. Assumes a chromedriver window is already open.\n",
    "#stop_scroll does nothing\n",
    "\n",
    "def get_html_scroll(url, stop_scroll):\n",
    "    driver.get(url)\n",
    "\n",
    "    SCROLL_PAUSE_TIME = .5\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    for i in range(50):\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            time.sleep(3)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "        last_height = new_height\n",
    "        \n",
    "    return driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a list of artist names (more precisely soundcloud's internal marker for them) contained in the html of a likes page. \n",
    "#The fact it concatenates this list to itself serves no real purpose before returning serves no real purpose.\n",
    "\n",
    "def parse_likes(html):\n",
    "    links = re.findall('<a class=\"sound__coverArt\" href=\"/\\S{,50}/', html)\n",
    "    links = [str[34:len(str)-1].split(\"/\")[0] for str in links]\n",
    "    print(len(links))\n",
    "    return np.column_stack((links, links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing but for reposts\n",
    "\n",
    "def parse_reposts(html):\n",
    "    links = re.findall('<a class=\"sound__coverArt\" href=\"/.{,100}/', html)\n",
    "    links = [str[34:len(str)-1].split(\"/\")[0] for str in links]\n",
    "    return np.column_stack((links,links))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing but for comments\n",
    "\n",
    "def parse_comments(html):\n",
    "    links = re.findall('a class=\"sc-link-light\" href=\"/.{,100}/', html)\n",
    "    links = [str[31:len(str)-1].split(\"/\")[0] for str in links]\n",
    "    return np.column_stack((links,links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing but for follows\n",
    "\n",
    "def parse_follows(html):\n",
    "    links = re.findall('<a href=\"/.{,100}\" class=\"userBadgeListItem__image\">', html)\n",
    "    links = [str[10:len(str)-35] for str in links]\n",
    "    return np.column_stack((links,links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the number of followers a user has from the html of a user's base account page.\n",
    "\n",
    "def parse_followers(html):\n",
    "    followers = re.findall('\"followers_count\":\\d{,50},', html)\n",
    "    num = int(followers[0][18:len(followers[0])-1])\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a user's display name from the html of a user's base account page.\n",
    "\n",
    "def parse_name(html):\n",
    "    name = re.findall('\"username\":\".{,200}\"', html_followers)[0]\n",
    "    name = name[12:]\n",
    "    name = name.split('\\\"')[0]\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the \"emerge date\" from the html of a user's tracks page. \"Emerge date\" is defined as the \n",
    "#first 15% quantile of a user's track upload dates.\n",
    "\n",
    "def parse_tracks(html):\n",
    " \n",
    "    dates = re.findall('datetime=\".{,25}\">', html)\n",
    "    dates = [str[10:len(str)-2] for str in dates]\n",
    "    dates = pd.to_datetime(dates)\n",
    "\n",
    "    #convert upload dates to unix time\n",
    "    unix_times = (dates - pd.Timestamp(\"1970-01-01 00:00:00+00:00\")) // pd.Timedelta('1s')\n",
    "    unix_times = unix_times.to_numpy()\n",
    "    unix_times = np.unique(unix_times) #reduce effects of album with multiple tracks\n",
    "\n",
    "    emerge_date = np.quantile(unix_times,.15)\n",
    "\n",
    "    emerge_date = datetime.utcfromtimestamp(emerge_date)\n",
    "    string_output = emerge_date.strftime('%m/%d/%Y') #convert from unix time to string\n",
    "    \n",
    "    \n",
    "    return string_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add newly encountered accounts to the \"seeds\" dataframe. will only add accounts that have not been \n",
    "#encountered before. the seeds dataframe is used to label the columns of the sparse_matrix data.\n",
    "\n",
    "def add_seeds(arr, seeds):\n",
    "    for i in range(arr.shape[0]):\n",
    "        search = seeds['links'] == arr[i,1]\n",
    "        if not any(search):\n",
    "            new_line = pd.DataFrame(data={'names': arr[i,0], 'links': arr[i,1], 'followers': 0}, index=[0])\n",
    "            seeds = seeds.append(new_line, ignore_index=True)\n",
    "\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handles the routine of collecting every interaction data type for a given account\n",
    "\n",
    "def scrape_data(sparse_matrix, seeds, i, followers):\n",
    "        \n",
    "    sparse_matrix.resize((sparse_matrix.shape[0]+1, seeds.shape[0])) #add row to sparse matrix\n",
    "    \n",
    "    for to_collect in [\"likes\", \"comments\", \"following\", \"reposts\"]:\n",
    "        url = \"https://soundcloud.com/\" + i + \"/\" + to_collect\n",
    "        html = get_html_scroll(url,False) #scroll down 50 times on page specified by url\n",
    "\n",
    "        if to_collect == 'likes':\n",
    "            data = parse_likes(html)\n",
    "        elif to_collect == 'comments':\n",
    "            data = parse_comments(html)\n",
    "        elif to_collect == 'following':\n",
    "            data = parse_follows(html)\n",
    "        elif to_collect == 'reposts':\n",
    "            data = parse_reposts(html)\n",
    "\n",
    "        seeds = add_seeds(data, seeds)\n",
    "        \n",
    "        sparse_matrix.resize((sparse_matrix.shape[0], seeds.shape[0]))\n",
    "\n",
    "        list = data[:,1]\n",
    "\n",
    "        #data from likes, reposts, follows, and comments are combined into a single sparse matrix\n",
    "        #with these weights rather than being stored separately and then combined later.\n",
    "        if to_collect == 'likes':\n",
    "            increment = 1\n",
    "        else:\n",
    "            increment = 3\n",
    "            \n",
    "        #a slightly more roundabout way of using .loc functions on a sparse matrix.\n",
    "        #remaining_seeds specifies row labels and seeds specifies column labels.\n",
    "        row_indexer = pd.Index(remaining_seeds['links'])    \n",
    "        row_ind = row_indexer.get_loc(str(i))   \n",
    "        col_indexer = pd.Index(seeds['links'])\n",
    "        \n",
    "        for j in list:\n",
    "            col_ind = col_indexer.get_loc(str(j))\n",
    "            sparse_matrix[row_ind, col_ind] += increment\n",
    "            \n",
    "    return (sparse_matrix, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS BLOCK WITH CAUTION IT WILL DELETE ALL YOUR PROGRESS\n",
    "\n",
    "#Reinitialize a run. Use this to start a run from zero. \n",
    "\n",
    "num = 0 #num specifies the index of remaining_seeds the scraper is currently at\n",
    "\n",
    "seeds = pd.read_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\seeds.csv\")\n",
    "\n",
    "remaining_seeds = pd.read_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\remaining_seeds.csv\")\n",
    "\n",
    "#lil_matrix format is used for incrementally constructing a sparse matrix\n",
    "sparse_matrix = scipy.sparse.lil_matrix((0,0))\n",
    "\n",
    "#num is saved to a simple text file\n",
    "file = open(\"C:\\\\soundcloud_project\\\\v3.0\\\\tracking_num.txt\",\"w\")\n",
    "file.write(str(0))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload an in-progress run\n",
    "\n",
    "sparse_matrix = scipy.sparse.load_npz(\"C:\\\\soundcloud_project\\\\v3.0\\\\sparse_matrix.npz\")\n",
    "sparse_matrix = sparse_matrix.tolil() \n",
    "\n",
    "seeds = pd.read_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\seeds.csv\") #specifies order of COLUMN labels\n",
    "\n",
    "#specifies order of ROW labels. also includes display name, followers, and emerge date\n",
    "remaining_seeds = pd.read_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\remaining_seeds.csv\") \n",
    "\n",
    "file = open(\"C:\\\\soundcloud_project\\\\v3.0\\\\tracking_num.txt\",\"r\")\n",
    "num = int(file.read())\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns the account most interacted with by the accounts in remaining_seeds, not\n",
    "#including the accounts already in remaining_seeds\n",
    "\n",
    "def sort_interactions(lil_matrix, seeds, remaining_seeds, num):\n",
    "    csc_matrix = lil_matrix.tocsc() #convert to csc to make summation along columns more efficient\n",
    "    sums = csc_matrix.sum(axis=0)\n",
    "    \n",
    "    df = pd.DataFrame(data=np.transpose(sums),index=seeds['links'],columns=['sums'])\n",
    "    df = df.drop(labels=remaining_seeds['links'], axis=0)\n",
    "    \n",
    "    max_idx = df.idxmax() \n",
    "    \n",
    "    return max_idx.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main control loop for scraper\n",
    "\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\pswjt\\\\Documents\\\\chromedriver\\\\chromedriver.exe')\n",
    "\n",
    "while num < 15000: \n",
    "    \n",
    "    #If there are accounts listed in remaining_seeds, use those for scraping.\n",
    "    if remaining_seeds.shape[0] > num: \n",
    "        i = remaining_seeds.iloc[num]['links']\n",
    "        \n",
    "    #If you reached the end of remaining_seeds, find the most interacted with account not already\n",
    "    #scraped, add it to remaining_seeds and scrape that account. Allows program to continually find\n",
    "    #new accounts without specifying them in a list. Susceptible to eventually moving to more \n",
    "    #\"mainstream\" artists which may not be desired.\n",
    "    else: \n",
    "        i = sort_interactions(sparse_matrix,seeds,remaining_seeds,num)\n",
    "        new_line = pd.DataFrame(data={'names': i, 'links': i, 'followers': 0, 'emerge_date': 0}, index=[0])\n",
    "        remaining_seeds = remaining_seeds.append(new_line, ignore_index=True)\n",
    "    \n",
    "    url = \"https://soundcloud.com/\" + i\n",
    "    driver.get(url)\n",
    "    html_followers = driver.page_source\n",
    "    \n",
    "    try: #If the url is broken for whatever reason, this try block will catch errors thrown\n",
    "        followers = parse_followers(html_followers)\n",
    "        remaining_seeds.at[num, 'followers'] = followers\n",
    "\n",
    "        name = parse_name(html_followers)\n",
    "        remaining_seeds.at[num, 'names'] = name\n",
    "\n",
    "        url = \"https://soundcloud.com/\" + i + \"/tracks\"\n",
    "        driver.get(url)\n",
    "\n",
    "        html_tracks = get_html_scroll(url, False)\n",
    "        emerge_date = parse_tracks(html_tracks)\n",
    "        remaining_seeds.at[num, 'emerge_date'] = emerge_date\n",
    "\n",
    "        sparse_matrix, seeds = scrape_data(sparse_matrix, seeds, i, followers)  \n",
    "        \n",
    "    except IndexError:\n",
    "        print('Link to account %s does not work. Skipping this account.' % i)\n",
    "        sparse_matrix.resize((sparse_matrix.shape[0]+1, seeds.shape[0]))\n",
    "        \n",
    "    except TypeError:\n",
    "        print('%s has no tracks. Skipping this account.' % i)\n",
    "        sparse_matrix.resize((sparse_matrix.shape[0]+1, seeds.shape[0]))\n",
    "        \n",
    "    finally:\n",
    "        print(remaining_seeds.iloc[num])\n",
    "        num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell after terminating program to save progress\n",
    "\n",
    "num -= 1 #included cause num is incremented in the finally block when the keyboardinterrupt\n",
    "#exception is thrown\n",
    "\n",
    "sparse_matrix_saveable = sparse_matrix.tocsr()\n",
    "scipy.sparse.save_npz('C:\\\\soundcloud_project\\\\v3.0\\\\sparse_matrix.npz', sparse_matrix_saveable)\n",
    "\n",
    "remaining_seeds.to_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\remaining_seeds.csv\", index=False)\n",
    "\n",
    "seeds.to_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\seeds.csv\", index=False)\n",
    "\n",
    "file = open(\"C:\\\\soundcloud_project\\\\v3.0\\\\tracking_num.txt\",\"w\")\n",
    "file.write(str(num))\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
