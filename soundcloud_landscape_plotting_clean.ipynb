{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all data\n",
    "\n",
    "sparse_matrix = scipy.sparse.load_npz(\"C:\\\\soundcloud_project\\\\v3.0\\\\sparse_matrix.npz\")\n",
    "\n",
    "seeds = pd.read_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\seeds.csv\") #column labels\n",
    "\n",
    "remaining_seeds = pd.read_csv(\"C:\\\\soundcloud_project\\\\v3.0\\\\remaining_seeds.csv\") #row labels\n",
    "\n",
    "sparse_matrix = sparse_matrix.tocsr()\n",
    "\n",
    "#cuts out accounts that weren't gotten to by the scraper yet\n",
    "remaining_seeds = remaining_seeds[0:sparse_matrix.shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9774, 4)\n",
      "(8795, 4)\n"
     ]
    }
   ],
   "source": [
    "#filter out accounts with a sum interaction score of less than 40\n",
    "\n",
    "sums = sparse_matrix.sum(axis=1)\n",
    "mask = sums > 40\n",
    "mask = np.ravel(mask)\n",
    "\n",
    "print(remaining_seeds.shape)\n",
    "sparse_matrix = sparse_matrix[mask,:]\n",
    "remaining_seeds = remaining_seeds[mask]\n",
    "print(remaining_seeds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "437\n",
      "8358\n",
      "(8358, 4)\n"
     ]
    }
   ],
   "source": [
    "#remove accounts which did not get properly assigned an emerge date of followers count\n",
    "\n",
    "mask_2 = remaining_seeds['emerge_date'] == 'a'\n",
    "\n",
    "mask_3 = remaining_seeds['followers'] == 0\n",
    "\n",
    "mask_final = ~(mask_2 | mask_3)\n",
    "\n",
    "remaining_seeds = remaining_seeds[mask_final]\n",
    "sparse_matrix = sparse_matrix[mask_final,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data with the sum of each rows interactions\n",
    "\n",
    "sums = sparse_matrix.sum(axis=1)\n",
    "\n",
    "recips = np.reciprocal(sums.astype('float'))\n",
    "\n",
    "mat_float_normalize = sparse_matrix.astype('float').multiply(recips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8095, 489554)\n",
      "(8095, 4)\n"
     ]
    }
   ],
   "source": [
    "#Remove which give more than 40% of their interactions to a single account.\n",
    "\n",
    "maxes = mat_float_normalize.max(axis=1)\n",
    "\n",
    "maxes = maxes.todense()\n",
    "\n",
    "total_activity_mask = maxes < 0.4\n",
    "\n",
    "remaining_seeds = remaining_seeds[total_activity_mask]\n",
    "\n",
    "total_activity_mask = np.ravel(total_activity_mask)\n",
    "\n",
    "mat_float_normalize = mat_float_normalize.tocsr()[total_activity_mask, :]\n",
    "\n",
    "print(mat_float_normalize.shape)\n",
    "print(remaining_seeds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform initial dimensional reduction\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "\n",
    "arr_svd = svd.fit_transform(mat_float_normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run UMAP\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=100, min_dist=0.0001, metric='euclidean', low_memory=True)\n",
    "\n",
    "reduced = reducer.fit_transform(arr_svd) #due to memory issues this was actually done in Colab\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This was not used in any of the visualizations but these hdbscan settings seemed to cluster\n",
    "#the data relatively well.\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, min_samples=4, cluster_selection_epsilon=0.09)\n",
    "clusters = clusterer.fit_predict(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_seeds = remaining_seeds\n",
    "final_seeds = final_seeds.set_index('links')\n",
    "\n",
    "links = final_seeds.index\n",
    "urls = ['https://soundcloud.com/' + str for str in links]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     names  followers emerge_date\n",
      "links                                                            \n",
      "kggn                                  kuru      10301   1/10/2020\n",
      "axxturel          @kingaxxturel #lastkings      15762   2/21/2019\n",
      "paulonrecords                         ⠀⠀⠀⠀       2142   10/2/2015\n",
      "blackwinterwells          blackwinterwells      11432   2/20/2020\n",
      "djphat1996                         DJ PHAT      27569   10/5/2018\n",
      "...                                    ...        ...         ...\n",
      "typicaledmon                         Edmon        660  09/08/2019\n",
      "ukaju                                ujaku        597  10/09/2016\n",
      "bandedupkelo                  BandedUpKelo       1355  08/21/2016\n",
      "sleeplessxcity            sleepless X city        219  05/09/2017\n",
      "1poohy                               Poohy        191           0\n",
      "\n",
      "[8095 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#assign generation\n",
    "print(final_seeds)\n",
    "generations = list(range(final_seeds.shape[0]))\n",
    "\n",
    "for i in range(final_seeds.shape[0]):\n",
    "    if pd.to_datetime(final_seeds.iloc[i]['emerge_date'], errors='coerce') < pd.to_datetime('01/01/2013'):\n",
    "        generations[i] = 0\n",
    "    elif pd.to_datetime(final_seeds.iloc[i]['emerge_date'], errors='coerce') < pd.to_datetime('01/01/2015'):\n",
    "        generations[i] = 1\n",
    "    elif pd.to_datetime(final_seeds.iloc[i]['emerge_date'], errors='coerce') < pd.to_datetime('01/01/2017'):\n",
    "        generations[i] = 2\n",
    "    elif pd.to_datetime(final_seeds.iloc[i]['emerge_date'], errors='coerce') < pd.to_datetime('01/01/2019'):\n",
    "        generations[i] = 3\n",
    "    elif pd.to_datetime(final_seeds.iloc[i]['emerge_date'], errors='coerce') < pd.to_datetime('01/01/2021'):\n",
    "        generations[i] = 4\n",
    "    else:\n",
    "        generations[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtains the position of each point within each individual generation/trace.\n",
    "#not necessary when graph was just a single trace but needed for search function\n",
    "\n",
    "pos_within_trace = np.array(list(range(len(generations))))\n",
    "nums = np.array(list(range(len(generations))))\n",
    "\n",
    "for i in range(6):\n",
    "    mask = generations == i\n",
    "    pos_within_trace[mask] = nums[0:len(pos_within_trace[mask])]\n",
    "    pos_within_trace[mask]\n",
    "\n",
    "pos_within_trace = list(pos_within_trace)\n",
    "pos_within_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forms the plotly graph\n",
    "\n",
    "from plotly.offline import plot\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import re\n",
    "\n",
    "links = final_seeds.index\n",
    "urls = ['https://soundcloud.com/' + str for str in links]\n",
    "\n",
    "urls = np.array(urls)\n",
    "generations = np.array(generations)\n",
    "\n",
    "#make hover labels\n",
    "labels_2 = ['<b>' + str + '</b><br><sub>followers: ' for str in final_seeds['names']]\n",
    "for i in range(final_seeds.shape[0]):\n",
    "    labels_2[i] = labels_2[i] + str(final_seeds.iloc[i]['followers'])\n",
    "    labels_2[i] = labels_2[i] + '   ||   Generation ' + str(generations[i] + 1) + '</sub>'\n",
    "\n",
    "labels_2 = np.array(labels_2)\n",
    "\n",
    "#make searchable text strings, just concatenates the display name with the url separated by \n",
    "search_text = []\n",
    "for i in range(final_seeds.shape[0]):\n",
    "    search_text.append((final_seeds.index[i] + '|||' + final_seeds.iloc[i]['names']).lower())\n",
    "\n",
    "# mapbox_access_token = '...'\n",
    "\n",
    "# Build scattermapbox trace and store URL's in the customdata\n",
    "# property. The values of this list will be easy to get to in the\n",
    "# JavaScript callback below\n",
    "\n",
    "data = []\n",
    "\n",
    "#manually get colors for gradient from gen 1 -> 6\n",
    "colors = ['#0d0887', '#6c01a7', '#b22d8f', '#e26761', '#fcaa36', '#f1f822']\n",
    "names = ['Generation I (pre-2013)', 'Generation II (2013-2014)', 'Generation III (2015-2016)', 'Generation IV (2017-2018)', 'Generation V (2019-2020)', 'Generation VI (2021-present)']\n",
    "\n",
    "#originally this was done in one single trace, but each generation was divided into an individual\n",
    "#trace to make the legend work\n",
    "for i in range(6):\n",
    "    mask = np.array(generations) == i\n",
    "    data_toappend = [\n",
    "        go.Scatter(\n",
    "            x=reduced[mask,0], \n",
    "            y=reduced[mask,1],\n",
    "            hovertext=labels_2[mask], \n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                color=str(colors[i])\n",
    "            ),\n",
    "            mode='markers',\n",
    "            customdata=urls[mask],\n",
    "            name = names[i]\n",
    "        )\n",
    "    ]\n",
    "    data.append(data_toappend)\n",
    "\n",
    "\n",
    "# Build layout\n",
    "layout = go.Layout(\n",
    "    hovermode='closest',\n",
    "    title=\"The Shape of SoundCloud<br><sub>Generated by scraping recent SoundCloud activity (April-May 2021) from over 8,000 artists. Read more <a href'https://pswjt1.medium.com/visualizing-the-shape-of-soundcloud-communities-with-web-scraping-and-machine-learning-cc1c5d948f78'>here.</a>\",\n",
    "    xaxis_title =\"<sub>Made by <a href='https://twitter.com/pswjt'>@pswjt</a>\",\n",
    "    \n",
    "    #there are definitely more scenes you could define, intentionally left the labels a \n",
    "    #little vague\n",
    "    annotations = [go.layout.Annotation(x=5.8, y=0.5, text='Digicore', showarrow=False, font={'size':16}),\n",
    "                   go.layout.Annotation(x=1.7, y=1.0, text='Plugg', showarrow=False, font={'size':16}),\n",
    "   #                go.layout.Annotation(x=0.4, y=3.6, text='Emo Rap', showarrow=False, font={'size':16}),\n",
    "                   go.layout.Annotation(x=0.6, y=8.4, text='Wave', showarrow=False, font={'size':16}),\n",
    "                   go.layout.Annotation(x=10.2, y=4.3, text='Dubstep', showarrow=False, font={'size':16}),\n",
    "                  ]\n",
    ") \n",
    "\n",
    "\n",
    "# Build Figure\n",
    "fig = go.Figure(\n",
    "    layout=layout,\n",
    ")\n",
    "\n",
    "for trace in data:\n",
    "    fig.add_trace(trace[0])\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        yanchor='bottom',\n",
    "        y=0.03,\n",
    "        xanchor='right',\n",
    "        x=0.99\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=False,zeroline=False,visible=False)\n",
    "fig.update_yaxes(showgrid=False,zeroline=False,visible=False)\n",
    "\n",
    "\n",
    "fig.update_layout(template='plotly_white')\n",
    "\n",
    "#prepares the search strings and generation assignments for injection into plotly javascript code\n",
    "links_str = str(search_text) + \";\"\n",
    "generations_str = str(list(generations)) + \";\"\n",
    "\n",
    "# Get HTML representation of plotly.js and this figure\n",
    "plot_div = plot(fig, output_type='div', include_plotlyjs=True)\n",
    "\n",
    "# Get id of html div element that looks like\n",
    "# <div id=\"301d22ab-bfba-4621-8f5d-dc4fd855bb33\" ... >\n",
    "res = re.search('<div id=\"([^\"]*)\"', plot_div)\n",
    "div_id = res.groups()[0]\n",
    "\n",
    "# Build JavaScript callback for handling clicks\n",
    "# and opening the URL in the trace's customdata \n",
    "js_callback = \"\"\"\n",
    "<div id=\"Search box\" style=\"z-index=100; position:relative; margin-top: -3%;\"> \n",
    "<input type=\"text\" id=\"inputText\">\n",
    "<button onclick=\"search()\" id=\"Search\">Search</button>\n",
    "<span id=\"status\"></span>\n",
    "</div>\n",
    "<script>\n",
    "\n",
    "var input = document.getElementById('inputText'); \n",
    "input.addEventListener(\"keyup\", function(event) {{\n",
    "    if (event.keyCode === 13) {{\n",
    "        event.preventDefault();\n",
    "        document.getElementById(\"Search\").click();\n",
    "    }}\n",
    "}});\n",
    "\n",
    "var plot_element = document.getElementById(\"{div_id}\");\n",
    "plot_element.on('plotly_click', function(data){{\n",
    "    console.log(data);\n",
    "    var point = data.points[0];\n",
    "    if (point) {{\n",
    "        console.log(point.customdata);\n",
    "        window.open(point.customdata);\n",
    "    }}\n",
    "}})\n",
    "\n",
    "var generations = {generations}\n",
    "var points = {links}\n",
    "var pos_within_trace = {pos_within_trace}\n",
    "\n",
    "var dict = {{}};\n",
    "points.forEach((points, i) => result[points] = generations[i]);\n",
    "console.log(dict);\n",
    "\n",
    "function search() {{\n",
    "    document.getElementById(\"status\").innerHTML = '';\n",
    "    var i = 0;\n",
    "    var found = [];\n",
    "    var myDiv = document.getElementsByClassName(\"js-plotly-plot\")[0];\n",
    "    var text = document.getElementById(\"inputText\").value.toLowerCase();\n",
    "    for (i = 0; i < points.length; i += 1) {{\n",
    "        if (points[i].includes(text)) {{\n",
    "            found.push({{curveNumber: generations[i], pointNumber: pos_within_trace[i]}});\n",
    "            console.log(found);\n",
    "        }}\n",
    "    }}\n",
    "\n",
    "    if (found.length == 0){{\n",
    "        document.getElementById(\"status\").innerHTML = ' Artist not found'\n",
    "    }} else if (found.length > 20) {{\n",
    "        document.getElementById(\"status\").innerHTML = ' Search something more specific'\n",
    "    }} else {{\n",
    "        Plotly.Fx.hover(myDiv, found);\n",
    "    }}\n",
    "    \n",
    "}}\n",
    "</script>\n",
    "\"\"\".format(div_id=div_id, links=links_str, pos_within_trace=pos_within_trace, generations=list(generations))\n",
    "\n",
    "# Build HTML string\n",
    "html_str = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "{plot_div}\n",
    "{js_callback}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\".format(plot_div=plot_div, js_callback=js_callback)\n",
    "\n",
    "#Write out HTML file\n",
    "with open('C:\\\\soundcloud_project\\\\soundcloud_map_v3_final.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_str)\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes mask for if each column header is found in the rows\n",
    "\n",
    "isin_mask = seeds['links'].isin(remaining_seeds['links'])\n",
    "isin_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forms list of edges from sparse matrix for construction of network graph\n",
    "\n",
    "edge_list = []\n",
    "\n",
    "for i in range(remaining_seeds.shape[0]):\n",
    "    \n",
    "    mask = sparse_matrix[i,:] > 0\n",
    "    mask = mask.todense()\n",
    "    mask = np.ravel(mask)\n",
    "    mask = mask & isin_mask\n",
    "    \n",
    "    i_name = remaining_seeds.iloc[i]['links']\n",
    "    j_names = np.ravel(seeds.loc[mask]['links'])\n",
    "    \n",
    "    values = np.ravel(sparse_matrix[i,mask].todense())\n",
    "    \n",
    "    print(i_name)\n",
    "    for j in range(j_names.shape[0]):\n",
    "        j_name = j_names[j]\n",
    "        if values[j] > 3: #ignores values 3 or below for edge construction, too many edges otherwise\n",
    "            edge_list.append((i_name,j_name,values[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#greates network graph in networkx library and exports to gephi. \n",
    "#openord diagram was used to create network graph layout and the result was exported to \n",
    "#sigma.js format.\n",
    "\n",
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_nodes_from(remaining_seeds['links'])\n",
    "\n",
    "rem_seeds = remaining_seeds.set_index('links')\n",
    "name_dict = rem_seeds['names'].to_dict()\n",
    "follow_dict = rem_seeds['followers'].to_dict()\n",
    "emerge_dict = rem_seeds['emerge_date'].to_dict()\n",
    "\n",
    "G.add_weighted_edges_from(edge_list)\n",
    "\n",
    "nx.set_node_attributes(G, name_dict, 'label')\n",
    "nx.set_node_attributes(G, follow_dict, 'followers')\n",
    "nx.set_node_attributes(G, emerge_dict, 'emerge date')\n",
    "nx.set_node_attributes(G, url_dict, 'url')\n",
    "\n",
    "nx.write_gexf(G, path='C:\\\\soundcloud_project\\\\v3.0\\\\gexf_sc.gexf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
